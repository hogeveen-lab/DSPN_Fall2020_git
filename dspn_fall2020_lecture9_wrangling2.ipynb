{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science in Psychology & Neuroscience (DSPN): \n",
    "\n",
    "## Lecture 9. Data Wrangling (part 2)\n",
    "\n",
    "### Date: September 22, 2020\n",
    "\n",
    "### To-Dos From Last Class:\n",
    "\n",
    "* Download data for today's wrangling session #1 dataset from <a href=\"https://github.com/hogeveen-lab/DSPN_Fall2020_git\">Github</a>\n",
    "\n",
    "### Today:\n",
    "\n",
    "* Data wrangling in Pandas (stealing heavily from this <a href=\"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\">Cheatsheet</a>)\n",
    "    * Last part of last class: Combining data frames\n",
    "* Wrangle some real data\n",
    "\n",
    "### Homework\n",
    "\n",
    "* Download Assignment #3 start kit data\n",
    "    * Beginner level\n",
    "    * Advanced level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling in Pandas\n",
    "\n",
    "## (finishing from last class) 5. Combining Data Sets \n",
    "\n",
    "<img src=\"img/combining_data.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge LEFT (right --> left; lose unique data from right)\n",
      "  pid  var1  var2\n",
      "0  P1    70  43.0\n",
      "1  P2    43  49.0\n",
      "2  P3    47   NaN\n",
      "Merge RIGHT (left --> right; lose unique data from left)\n",
      "  pid  var1  var2\n",
      "0  P1  70.0    43\n",
      "1  P2  43.0    49\n",
      "2  P4   NaN    33\n",
      "Merge INNER (lose unique data from either df)\n",
      "  pid  var1  var2\n",
      "0  P1    70    43\n",
      "1  P2    43    49\n",
      "Merge OUTER (retain all data)\n",
      "  pid  var1  var2\n",
      "0  P1  70.0  43.0\n",
      "1  P2  43.0  49.0\n",
      "2  P3  47.0   NaN\n",
      "3  P4   NaN  33.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# func for generating random int\n",
    "def random_integer(x,n): # where x is an empty list, and n is the # of vals we need\n",
    "    for i in range(n):\n",
    "        x.append(np.random.randint(25,75))\n",
    "    return x\n",
    "\n",
    "# running the func and checking the output\n",
    "x = []\n",
    "random_integer(x,6)\n",
    "print(x)\n",
    "\n",
    "# putting together some test data frames\n",
    "df1 = pd.DataFrame({'pid' : ['P1','P2','P3'],\n",
    "                   'var1' : [x[0],x[1],x[2]]})\n",
    "df2 = pd.DataFrame({'pid' : ['P1','P2','P4'],\n",
    "                   'var2' : [x[3],x[4],x[5]]})\n",
    "\n",
    "### Standard approach #1 -- join matching rows from df2 to df1\n",
    "print('Merge LEFT (right --> left; lose unique data from right)')\n",
    "print(pd.merge(df1,df2,how='left',on='pid'))\n",
    "\n",
    "### Standard approach #2 -- join matching rows from df1 to df2\n",
    "print('Merge RIGHT (left --> right; lose unique data from left)')\n",
    "print(pd.merge(df1,df2,how='right',on='pid'))\n",
    "\n",
    "### Standard approach #3 -- retain rows present in BOTH dfs\n",
    "print('Merge INNER (lose unique data from either df)')\n",
    "print(pd.merge(df1,df2,how='inner',on='pid'))\n",
    "\n",
    "### Standard approach #4 -- retain rows present in ANY dfs\n",
    "print('Merge OUTER (retain all data)')\n",
    "print(pd.merge(df1,df2,how='outer',on='pid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle some real data\n",
    "\n",
    "## Breaking into 8 code chunks\n",
    "\n",
    "1. Import packages\n",
    "2. Setting paths to the first level data\n",
    "3. Load a test subject to make sense of things\n",
    "4. Iterate through to load the first level data\n",
    "    * Concatenate all together to create one data frame to rule them all\n",
    "5. Merge with questionnaire data\n",
    "6. Write to trial-level allsubjects csv\n",
    "#### Pick up next class..\n",
    "7. Compute summary measures\n",
    "8. Save to summary allsubjects csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1 --> Importing data wrangling packages I often use\n",
    "\n",
    "# Packages that are key for interacting with the OS and matching filename patterns\n",
    "import os\n",
    "from glob import glob # only need the glob subpackage from glob\n",
    "\n",
    "# Packages that are key for data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2 --> setting paths to the first level data\n",
    "\n",
    "# get current working directory\n",
    "script_dir = os.getcwd()\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Go above current working directory and\n",
    "first_dir = os.path.join(base_dir,'misc_exercises/imitation_inhibition_paradigm/data/first') #misc_exercises/ for git\n",
    "# first_dir = os.path.join(base_dir,'exercises/imitation_inhibition_paradigm/data/first') #misc_exercises/ for git\n",
    "P_file_pattern = 'P*.txt'\n",
    "second_dir = os.path.join(base_dir,'misc_exercises/imitation_inhibition_paradigm/data/second')\n",
    "# second_dir = os.path.join(base_dir,'exercises/imitation_inhibition_paradigm/data/second')\n",
    "questionnaire_file = os.path.join(second_dir,'ait_questionnaires.csv')\n",
    "\n",
    "# Using glob to find all participant data files\n",
    "all_files = glob(os.path.join(first_dir,P_file_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many rows in initial loaded data frame: 521\n",
      "How many rows in key release filtered data frame: 101\n",
      "How many rows in no-double-response filtered data frame: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyhogeveen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jeremyhogeveen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### Part 3 --> Loading in a test subject to make sense of things\n",
    "\n",
    "# Reading in the data\n",
    "sample_df = pd.read_csv(all_files[0], error_bad_lines=False, skiprows=5, sep='\\t') \n",
    "print('How many rows in initial loaded data frame:',len(sample_df)) # What things might cause this to not == 100?\n",
    "\n",
    "# Filtering the data down to just the experimental block rows\n",
    "sample_df = sample_df[sample_df['Name.1']==\"AI_Block\"]\n",
    "sample_df.loc[:, 'Finger':'Repeated']\n",
    "sample_df.loc[50:300, :]\n",
    "\n",
    "# Filtering the df down to just the key release responses\n",
    "sample_df_releases = sample_df[sample_df['Released']=='Released'] \n",
    "\n",
    "# How many key release responses do we have?\n",
    "print('How many rows in key release filtered data frame:',len(sample_df_releases)) # What things might cause this to not == 100? For now, just worry baout double responses. For this task, error rates so low that miss response trials not really important.\n",
    "# print(sample_df_releases)\n",
    "\n",
    "# Identifying double responses\n",
    "sample_df_releases['shift'] = sample_df_releases['Name.2'].shift() # creating a new column ('shift') based on the next row of our trial name column. \"SettingWithCopyWarning\".\n",
    "# print(sample_df_releases[['Name.2','shift']]) # checking that it worked, show them shift(-1) \n",
    "sample_df_releases['double_response'] = np.where(sample_df_releases['shift']==sample_df_releases['Name.2'], 1, 0) # using a numpy where conditional to identify double responses\n",
    "\n",
    "# Checking that the double response thing worked\n",
    "test_df = sample_df_releases[sample_df_releases['Name.2']=='AI_Trial, 2']\n",
    "# print(test_df[['Name.2','shift','double_response']]) # checking that it worked, show them shift(-1)\n",
    "\n",
    "# Filtering our double response trials\n",
    "sample_df_releases_nodouble = sample_df_releases[sample_df_releases['double_response']==0] \n",
    "print('How many rows in no-double-response filtered data frame:',len(sample_df_releases_nodouble)) # Seeing if we have the right # of rows now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Group Name    Name.1        Name.2  \\\n",
      "49   Main Group   P8  AI_Block   AI_Trial, 7   \n",
      "54   Main Group   P8  AI_Block  AI_Trial, 10   \n",
      "58   Main Group   P8  AI_Block   AI_Trial, 5   \n",
      "63   Main Group   P8  AI_Block   AI_Trial, 9   \n",
      "67   Main Group   P8  AI_Block   AI_Trial, 3   \n",
      "..          ...  ...       ...           ...   \n",
      "499  Main Group   P8  AI_Block   AI_Trial, 3   \n",
      "504  Main Group   P8  AI_Block   AI_Trial, 9   \n",
      "509  Main Group   P8  AI_Block   AI_Trial, 7   \n",
      "514  Main Group   P8  AI_Block   AI_Trial, 6   \n",
      "519  Main Group   P8  AI_Block  AI_Trial, 10   \n",
      "\n",
      "                                Name.3 Response Key  Released  \\\n",
      "49              AI_Blue (7, i5inc.bmp)    index   v  Released   \n",
      "54            AI_Blue (10, m5base.bmp)   middle   b  Released   \n",
      "58       AI_Final_Stage (5, i4con.bmp)    index   v  Released   \n",
      "63             AI_Blue (9, i5base.bmp)    index   v  Released   \n",
      "67   AI_Final_Stage (3, i4baseinc.bmp)    index   v  Released   \n",
      "..                                 ...      ...  ..       ...   \n",
      "499         AI_Blue (3, i5baseinc.bmp)    index   v  Released   \n",
      "504            AI_Blue (9, i5base.bmp)    index   v  Released   \n",
      "509             AI_Blue (7, i5inc.bmp)    index   v  Released   \n",
      "514             AI_Blue (6, m5con.bmp)   middle   b  Released   \n",
      "519           AI_Blue (10, m5base.bmp)   middle   b  Released   \n",
      "\n",
      "                Response.1 Code  Time  (Trial Variable)  Finger  Congruence  \\\n",
      "49   (based on code value)    C   756               NaN       1           4   \n",
      "54   (based on code value)    C   663               NaN       2           0   \n",
      "58   (based on code value)    C   532               NaN       1           3   \n",
      "63   (based on code value)    C   616               NaN       1           0   \n",
      "67   (based on code value)    C   536               NaN       1           2   \n",
      "..                     ...  ...   ...               ...     ...         ...   \n",
      "499  (based on code value)    C   702               NaN       1           2   \n",
      "504  (based on code value)    C   669               NaN       1           0   \n",
      "509  (based on code value)    C   729               NaN       1           4   \n",
      "514  (based on code value)    C   693               NaN       2           3   \n",
      "519  (based on code value)    C   691               NaN       2           0   \n",
      "\n",
      "     Repeated  Correct         shift  double_response  \n",
      "49          1      NaN           NaN                0  \n",
      "54          1      NaN   AI_Trial, 7                0  \n",
      "58          1      NaN  AI_Trial, 10                0  \n",
      "63          1      NaN   AI_Trial, 5                0  \n",
      "67          1      NaN   AI_Trial, 9                0  \n",
      "..        ...      ...           ...              ...  \n",
      "499        10      NaN   AI_Trial, 4                0  \n",
      "504        10      NaN   AI_Trial, 3                0  \n",
      "509        10      NaN   AI_Trial, 9                0  \n",
      "514        10      NaN   AI_Trial, 7                0  \n",
      "519        10      NaN   AI_Trial, 6                0  \n",
      "\n",
      "[101 rows x 18 columns]\n",
      "49     1\n",
      "54     2\n",
      "58     1\n",
      "63     1\n",
      "67     1\n",
      "      ..\n",
      "499    1\n",
      "504    1\n",
      "509    1\n",
      "514    2\n",
      "519    2\n",
      "Name: Finger, Length: 101, dtype: int64\n",
      "[1 2 1 1 1 1 2 2 2 2 1 2 2 2 1 2 2 1 1 1 2 1 2 2 1 1 2 1 2 1 2 1 2 2 1 1 2\n",
      " 2 1 1 1 1 2 1 1 1 2 2 2 2 1 2 2 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 2 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 2 1 1 2 1 2 1 2 1 2 1 2 2 1 2 1 1 1 2 2]\n",
      "[1 2 1 1 1 1 2 2 2 2 1 2 2 2 1 2 2 1 1 1 2 1 2 2 1 1 2 1 2 1 2 1 2 2 1 1 2\n",
      " 2 1 1 1 1 2 1 1 1 2 2 2 2 1 2 2 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 2 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 2 1 1 2 1 2 1 2 1 2 1 2 2 1 2 1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating that Pandas data frames are a collection of series, which are different ways of storing arrays\n",
    "\n",
    "sample_df_releases # data frame\n",
    "sample_df_releases['Finger'] # Series w/in the data frame\n",
    "sample_df_releases['Finger'].values # converting the Data Frame to a numpy array\n",
    "np.array([1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1,\n",
    "       2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1,\n",
    "       1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2,\n",
    "       2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1,\n",
    "       2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyhogeveen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the participant counter from our loop: 48 should be roughly equivalent to our # of rows / 100: 47.45\n"
     ]
    }
   ],
   "source": [
    "### Part 4 --> Iterating through to get all the first level data, concatenating into allsubs data frame\n",
    "\n",
    "pid_counter = 1\n",
    "dfs_list = [] # creating a list of pandas objects\n",
    "\n",
    "for cur_file in all_files:\n",
    "    # Copying same logic from our test subject\n",
    "#     print(cur_file)\n",
    "    cur_df = pd.read_csv(cur_file, error_bad_lines=False, skiprows=5, sep='\\t') \n",
    "    cur_df_releases = cur_df[(cur_df['Released']=='Released') & (cur_df['Name.1']==\"AI_Block\")] \n",
    "#     print('How many rows in key release filtered data frame:',cur_df_releases['Congruence'].count()) # What things might cause this to not == 100? For now, just worry baout double responses. For this task, error rates so low that miss response trials not really important.\n",
    "    cur_df_releases['double_response'] = np.where(cur_df_releases['Name.2'].shift()==cur_df_releases['Name.2'], 1, 0) # faster way to find double responses\n",
    "    cur_df_releases_nodouble = cur_df_releases[cur_df_releases['double_response']==0] \n",
    "#     print('How many rows in no-double-response filtered data frame:',cur_df_releases_nodouble['Congruence'].count()) # Seeing if we have the right # of rows now\n",
    "    # Appending all the data into a data frame\n",
    "    dfs_list.append(cur_df_releases_nodouble)\n",
    "    pid_counter+=1\n",
    "\n",
    "# Concatenate all DFs together along the row axis\n",
    "allsubs_df = pd.concat(dfs_list, axis=0)\n",
    "\n",
    "# Checking what we got and making sure it makes sense given how many trials we should have\n",
    "# print(dfs_list)\n",
    "# print(allsubs_df)\n",
    "print('the participant counter from our loop:',pid_counter-1,'should be roughly equivalent to our # of rows / 100:',allsubs_df['Congruence'].count() / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pid  questionnaire_1  questionnaire_2  questionnaire_3  questionnaire_4  \\\n",
      "0    P8               62               22               74               37   \n",
      "1    P9                0               60               95               30   \n",
      "2   P49                0               36               88               13   \n",
      "3   P48                9               82                6               96   \n",
      "4   P13               60               69               15               62   \n",
      "5   P12               57               54               25               76   \n",
      "6   P38               66                9               63               35   \n",
      "7   P10               21               76               76               70   \n",
      "8   P11               22               20               92               57   \n",
      "9   P39               18               69               40               14   \n",
      "10  P15               71               75               19               59   \n",
      "11  P29               51               71               46               50   \n",
      "12  P28               10                8               13               96   \n",
      "13  P14               85               20               35               78   \n",
      "14  P16               30               50                5               51   \n",
      "15  P17               51               55               95               81   \n",
      "16  P32               67               44               44               41   \n",
      "17  P26               68               42               35               13   \n",
      "18  P27               69               96                9               86   \n",
      "19  P33               50               42                8                6   \n",
      "20  P19               83               20               65               84   \n",
      "21  P25               56               83               79               36   \n",
      "22  P31               58               18               88               14   \n",
      "23  P30               70               94               84               55   \n",
      "24  P24               98               16               88               75   \n",
      "25  P18               83                4               85               57   \n",
      "26  P20               85               10               70               99   \n",
      "27  P34               81               14               20               88   \n",
      "28  P35               38               58               49               25   \n",
      "29  P21               92               69               90               28   \n",
      "30  P37               63               66                7               56   \n",
      "31  P23                2                0               30               66   \n",
      "32  P22               35               24               47               84   \n",
      "33  P36               61                5               10               12   \n",
      "34  P45               70               41               41               51   \n",
      "35   P2               64               48               47               66   \n",
      "36   P3               47               80               27               67   \n",
      "37  P44               46               47               18               55   \n",
      "38  P46               73               80               92               84   \n",
      "39   P1               63               11               45               37   \n",
      "40  P47               60               99               50               45   \n",
      "41  P43               95               87               13               64   \n",
      "42   P5               19               48               82               14   \n",
      "43  P42               60               91               70               93   \n",
      "44  P40               48               37               20               15   \n",
      "45   P7               35               14               12               81   \n",
      "46   P6               69                3               59               37   \n",
      "47  P41               74               78               11               82   \n",
      "\n",
      "    questionnaire_5  questionnaire_6  questionnaire_7  questionnaire_8  \\\n",
      "0                62               32               46               56   \n",
      "1                68               29               93               52   \n",
      "2                14               20               36                5   \n",
      "3                18               66               87               34   \n",
      "4                88               29               37               74   \n",
      "5                54               50                2               92   \n",
      "6                97               42               44               61   \n",
      "7                14               81               44               57   \n",
      "8                36               34               90               30   \n",
      "9                12               88               53               31   \n",
      "10               15               36               20                2   \n",
      "11               94               71               70               91   \n",
      "12               35               18               65               48   \n",
      "13               94               25               72               47   \n",
      "14               76               78               54               29   \n",
      "15               92               89               92               83   \n",
      "16               89               99               14               47   \n",
      "17               40               34               48               44   \n",
      "18                8               28               80               36   \n",
      "19               56               64                2               65   \n",
      "20               75               73               56               62   \n",
      "21               44               44               82               53   \n",
      "22               80               78               26                8   \n",
      "23               57               12               14               70   \n",
      "24               79               27               65               24   \n",
      "25               99               59               62               31   \n",
      "26               61               31                0               42   \n",
      "27               85               12               44               63   \n",
      "28               23               77               34               11   \n",
      "29               60               62                8               90   \n",
      "30               85               22               19               81   \n",
      "31               28               28               47               86   \n",
      "32               68               46               20               47   \n",
      "33               48                3               50               21   \n",
      "34               98               54               30               90   \n",
      "35               22               39               11               43   \n",
      "36               32               39                2               91   \n",
      "37                2               64                2               94   \n",
      "38               53               32               11               19   \n",
      "39               18               42               83               22   \n",
      "40               11               60               44               43   \n",
      "41               72               82               39               76   \n",
      "42               77               67                0               96   \n",
      "43                0               60               33               16   \n",
      "44               11               35               92               67   \n",
      "45               77                7               61               58   \n",
      "46               37               91               20               96   \n",
      "47               74               54                8               36   \n",
      "\n",
      "    questionnaire_9  questionnaire_10  \n",
      "0                43                78  \n",
      "1                55                64  \n",
      "2                78                12  \n",
      "3                22                75  \n",
      "4                 7                40  \n",
      "5                43                83  \n",
      "6                58                34  \n",
      "7                31                29  \n",
      "8                72                57  \n",
      "9                71                26  \n",
      "10               24                37  \n",
      "11               30                96  \n",
      "12               27                 5  \n",
      "13                1                19  \n",
      "14               50                25  \n",
      "15               81                 8  \n",
      "16               13                 2  \n",
      "17               63                25  \n",
      "18               51                32  \n",
      "19               74                74  \n",
      "20               35                74  \n",
      "21               92                37  \n",
      "22               43                97  \n",
      "23               67                65  \n",
      "24               89                22  \n",
      "25               25                25  \n",
      "26               24                 9  \n",
      "27               43                62  \n",
      "28               92                84  \n",
      "29               42                15  \n",
      "30               80                 0  \n",
      "31               56                62  \n",
      "32               97                25  \n",
      "33               29                13  \n",
      "34               60                96  \n",
      "35               47                23  \n",
      "36               17                23  \n",
      "37               44                89  \n",
      "38               39                 4  \n",
      "39               80                14  \n",
      "40               93                 5  \n",
      "41               75                 7  \n",
      "42               90                32  \n",
      "43               58                20  \n",
      "44               93                20  \n",
      "45               71                20  \n",
      "46               63                59  \n",
      "47               73                22  \n",
      "           Group  pid    Name.1        Name.2  \\\n",
      "0     Main Group   P8  AI_Block   AI_Trial, 7   \n",
      "1     Main Group   P8  AI_Block  AI_Trial, 10   \n",
      "2     Main Group   P8  AI_Block   AI_Trial, 5   \n",
      "3     Main Group   P8  AI_Block   AI_Trial, 9   \n",
      "4     Main Group   P8  AI_Block   AI_Trial, 3   \n",
      "...          ...  ...       ...           ...   \n",
      "4740  Main Group  P41  AI_Block   AI_Trial, 4   \n",
      "4741  Main Group  P41  AI_Block   AI_Trial, 8   \n",
      "4742  Main Group  P41  AI_Block   AI_Trial, 5   \n",
      "4743  Main Group  P41  AI_Block   AI_Trial, 6   \n",
      "4744  Main Group  P41  AI_Block   AI_Trial, 9   \n",
      "\n",
      "                                 Name.3 Response Key  Released  \\\n",
      "0                AI_Blue (7, i5inc.bmp)    index   v  Released   \n",
      "1              AI_Blue (10, m5base.bmp)   middle   b  Released   \n",
      "2         AI_Final_Stage (5, i4con.bmp)    index   v  Released   \n",
      "3               AI_Blue (9, i5base.bmp)    index   v  Released   \n",
      "4     AI_Final_Stage (3, i4baseinc.bmp)    index   v  Released   \n",
      "...                                 ...      ...  ..       ...   \n",
      "4740  AI_Final_Stage (4, m4baseinc.bmp)    index   v  Released   \n",
      "4741      AI_Final_Stage (8, m4inc.bmp)   middle   b  Released   \n",
      "4742      AI_Final_Stage (5, i4con.bmp)    index   v  Released   \n",
      "4743      AI_Final_Stage (6, m4con.bmp)   middle   b  Released   \n",
      "4744     AI_Final_Stage (9, i4base.bmp)    index   v  Released   \n",
      "\n",
      "                 Response.1 Code  ...  questionnaire_1  questionnaire_2  \\\n",
      "0     (based on code value)    C  ...               62               22   \n",
      "1     (based on code value)    C  ...               62               22   \n",
      "2     (based on code value)    C  ...               62               22   \n",
      "3     (based on code value)    C  ...               62               22   \n",
      "4     (based on code value)    C  ...               62               22   \n",
      "...                     ...  ...  ...              ...              ...   \n",
      "4740  (based on code value)    E  ...               74               78   \n",
      "4741  (based on code value)    C  ...               74               78   \n",
      "4742  (based on code value)    C  ...               74               78   \n",
      "4743  (based on code value)    C  ...               74               78   \n",
      "4744  (based on code value)    C  ...               74               78   \n",
      "\n",
      "      questionnaire_3  questionnaire_4  questionnaire_5  questionnaire_6  \\\n",
      "0                  74               37               62               32   \n",
      "1                  74               37               62               32   \n",
      "2                  74               37               62               32   \n",
      "3                  74               37               62               32   \n",
      "4                  74               37               62               32   \n",
      "...               ...              ...              ...              ...   \n",
      "4740               11               82               74               54   \n",
      "4741               11               82               74               54   \n",
      "4742               11               82               74               54   \n",
      "4743               11               82               74               54   \n",
      "4744               11               82               74               54   \n",
      "\n",
      "      questionnaire_7  questionnaire_8  questionnaire_9  questionnaire_10  \n",
      "0                  46               56               43                78  \n",
      "1                  46               56               43                78  \n",
      "2                  46               56               43                78  \n",
      "3                  46               56               43                78  \n",
      "4                  46               56               43                78  \n",
      "...               ...              ...              ...               ...  \n",
      "4740                8               36               73                22  \n",
      "4741                8               36               73                22  \n",
      "4742                8               36               73                22  \n",
      "4743                8               36               73                22  \n",
      "4744                8               36               73                22  \n",
      "\n",
      "[4745 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "### Part 5 --> Loading in the questionnaire data and merging it with behavioral data\n",
    "\n",
    "# renaming pid column in data frame\n",
    "# print(allsubs_df['Name'])\n",
    "allsubs_df = allsubs_df.rename(columns={\"Name\": \"pid\"})\n",
    "\n",
    "# Reading in the npi data data\n",
    "questionnaire_df = pd.read_csv(questionnaire_file)\n",
    "print(questionnaire_df)\n",
    "\n",
    "# Merging the npi and main df\n",
    "allsubs_df = pd.merge(allsubs_df,questionnaire_df,how='outer',on='pid')\n",
    "print(allsubs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 6 --> Write data to a csv\n",
    "\n",
    "# Writing the data to a second-level data frame that we will eventually play with in R\n",
    "out_filename = os.path.join(second_dir,'ait_trialwise.csv')\n",
    "allsubs_df.to_csv(out_filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
