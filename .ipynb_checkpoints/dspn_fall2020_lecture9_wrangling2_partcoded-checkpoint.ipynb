{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science in Psychology & Neuroscience (DSPN): \n",
    "\n",
    "## Lecture 9. Data Wrangling (part 2)\n",
    "\n",
    "### Date: September 22, 2020\n",
    "\n",
    "### To-Dos From Last Class:\n",
    "\n",
    "* Download data for today's wrangling session #1 dataset from <a href=\"https://github.com/hogeveen-lab/DSPN_Fall2020_git\">Github</a>\n",
    "\n",
    "### Today:\n",
    "\n",
    "* Data wrangling in Pandas (stealing heavily from this <a href=\"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\">Cheatsheet</a>)\n",
    "    * Last part of last class: Combining data frames\n",
    "* Wrangle some real data\n",
    "\n",
    "### Homework\n",
    "\n",
    "* Download Assignment #3 starter kit data\n",
    "    * Beginner level\n",
    "    * Advanced level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling in Pandas\n",
    "\n",
    "## (finishing from last class) 5. Combining Data Sets \n",
    "\n",
    "<img src=\"img/combining_data.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 42, 63, 57, 50, 25]\n",
      "Merge LEFT (right -->left; lost unique data from right)\n",
      "  pid  var1  var2\n",
      "0  P1    29  57.0\n",
      "1  P2    42  50.0\n",
      "2  P3    63   NaN\n",
      "Merge RIGHT (left --> right; lost unique data from left)\n",
      "  pid  var1  var2\n",
      "0  P1  29.0    57\n",
      "1  P2  42.0    50\n",
      "2  P4   NaN    25\n",
      "Merge INNER (lose unique data from EITHER data frame)\n",
      "  pid  var1  var2\n",
      "0  P1    29    57\n",
      "1  P2    42    50\n",
      "Merge OUTER (retain all data)\n",
      "  pid  var1  var2\n",
      "0  P1  29.0  57.0\n",
      "1  P2  42.0  50.0\n",
      "2  P3  63.0   NaN\n",
      "3  P4   NaN  25.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# func for generating random integer lists\n",
    "def random_integer(x,n):\n",
    "    for i in range(n):\n",
    "        x.append(np.random.randint(25,75))\n",
    "    return x\n",
    "\n",
    "# calling the function to generate random data\n",
    "x = []\n",
    "random_integer(x,6)\n",
    "print(x)\n",
    "\n",
    "# putting together the data in two separate data frames\n",
    "df1 = pd.DataFrame({'pid' : ['P1','P2','P3'],\n",
    "                   'var1' : [x[0],x[1],x[2]]})\n",
    "df2 = pd.DataFrame({'pid' : ['P1','P2','P4'],\n",
    "                   'var2' : [x[3],x[4],x[5]]})\n",
    "\n",
    "# Standard approach #1 \n",
    "print('Merge LEFT (right -->left; lost unique data from right)')\n",
    "print(pd.merge(df1,df2,how='left',on='pid'))\n",
    "\n",
    "# Standard approach #2 \n",
    "print('Merge RIGHT (left --> right; lost unique data from left)')\n",
    "print(pd.merge(df1,df2,how='right',on='pid'))\n",
    "\n",
    "# Standard approach #3 \n",
    "print('Merge INNER (lose unique data from EITHER data frame)')\n",
    "print(pd.merge(df1,df2,how='inner',on='pid'))\n",
    "\n",
    "# Standard approach #4 \n",
    "print('Merge OUTER (retain all data)')\n",
    "print(pd.merge(df1,df2,how='outer',on='pid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle some real data\n",
    "\n",
    "## Breaking into 8 code chunks\n",
    "\n",
    "1. Import packages\n",
    "2. Setting paths to the first level data\n",
    "3. Load a test subject to make sense of things\n",
    "4. Iterate through to load the first level data\n",
    "    * Concatenate all together to create one data frame to rule them all\n",
    "5. Merge with questionnaire data\n",
    "6. Write to trial-level allsubjects csv\n",
    "#### Pick up next class..\n",
    "7. Compute summary measures\n",
    "8. Save to summary allsubjects csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 -- import packages\n",
    "\n",
    "# data wrangling packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# packages that are key for interacting with the operating system\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 -- set up our filepaths\n",
    "\n",
    "# get current working directory\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# get data directory\n",
    "data_dir = os.path.join(script_dir,'misc_exercises/imitation_inhibition_paradigm/data')\n",
    "first_dir = os.path.join(data_dir,'first')\n",
    "second_dir = os.path.join(data_dir,'second')\n",
    "questionnaire_file = os.path.join(second_dir,'ait_questionnaires.csv')\n",
    "\n",
    "# filepath pattern\n",
    "P_file_pattern = 'P*.txt'\n",
    "\n",
    "# Using GLOB to identify all files that match our P_file_pattern\n",
    "P_full_path = os.path.join(first_dir,P_file_pattern)\n",
    "all_files = glob(P_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many rows in key release filtered data frame: 101\n",
      "How many rows in no-double-response filtered data frame: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyhogeveen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/jeremyhogeveen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### Part 3 --> Loading in a test subject to make sense of things\n",
    "\n",
    "# Reading in the data\n",
    "sample_df = pd.read_csv(all_files[0], skiprows=5, sep='\\t') #error_bad_lines=False, \n",
    "\n",
    "# filtering down to just the experimental block\n",
    "sample_df = sample_df[sample_df['Name.1']=='AI_Block']\n",
    "\n",
    "# filtering down to just the key releases\n",
    "sample_df_releases = sample_df[sample_df['Released']=='Released']\n",
    "\n",
    "# printing out the length of the df_releases \n",
    "print('How many rows in key release filtered data frame:',len(sample_df_releases))\n",
    "\n",
    "# Identifying double responses\n",
    "sample_df_releases['shift'] = sample_df_releases['Name.2'].shift()\n",
    "sample_df_releases['double_response'] = np.where(sample_df_releases['shift']==sample_df_releases['Name.2'], 1, 0) # using a numpy where conditional to identify double responses\n",
    "\n",
    "# Filtering our double response trials\n",
    "sample_df_releases_nodouble = sample_df_releases[sample_df_releases['double_response']==0] \n",
    "print('How many rows in no-double-response filtered data frame:',len(sample_df_releases_nodouble)) # Seeing if we have the right # of rows now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
